---
type: "to-read"
id: 20260127080138
created: 2026-01-27T08:04:38
source:
  - "https://mp.weixin.qq.com/s/-KyqfwSTgTEDjPTNLqpBvA"
tags:
reviewd: false
---
Original 运维 *2026年1月26日 21:50*

hi,我是南哥。

最近看到贝联珠贯发布的 AIOps K8s 专家分析系统,说实话有点震撼。

  

![Image](https://mmbiz.qpic.cn/mmbiz_png/K6fzwF0Fr1yxZeic8DvDNoT0ERR1tk2673Sg8oJj1Yia1bOge5KIjj010MPX9F2OpKN0EbAgDomZ4z2ibv8OpicSqw/640?wx_fmt=png&from=appmsg&watermark=1&tp=webp&wxfrom=5&wx_lazy=1#imgIndex=0)

  

用 AI 自动诊断 K8s 集群问题,这个方向确实很火。但我更好奇的是,市面上开源方案做到什么程度了?

花了两天时间,我扒了两个最火的开源项目: **k8sgpt** 和 **Kubernetes MCP Server** 。

一个在 GitHub 上 5.8k Star,一个是红帽容器团队出品。看起来都挺牛的,但用起来完全是两个路子。

今天就来说说它们到底有什么区别,以及普通运维该怎么选。

## 一. 先说 k8sgpt - 会自己看病的医生

k8sgpt 这个工具,你可以理解成一个"AI 诊断医生"。

它会主动扫描你的 K8s 集群,发现问题后调用 AI 给出人话解释。

比如你的 Pod 起不来了,它不只告诉你 "ImagePullBackOff",还会说:

> "镜像拉取失败了老哥,可能是镜像名写错了,或者你的镜像仓库没配认证信息。去检查下 deployment 的 image 字段吧。"

**核心工作流程**:

```
集群扫描 → 发现问题 → AI 解释 → 给出建议
```

它内置了一堆分析器(Analyzer),每个负责检查特定资源:

- **DeploymentAnalyzer**: 检查副本数是否正常
- **PodAnalyzer**: 看 Pod 状态健不健康
- **IngressAnalyzer**: 检查入口配置对不对
- **HpaAnalyzer**: 检查自动扩缩容配置

还能集成外部工具,比如:

- **Prometheus**: 分析监控指标异常
- **AWS EKS**: 检查 EKS 集群健康状态
- **Kyverno**: 检查策略合规性

**最牛的是什么?**

它支持超多 AI 后端:

- OpenAI、Azure OpenAI
- AWS Bedrock、Google Gemini
- 国产的智谱 GLM、百川、Kimi

换句话说,你不用非得花大价钱用 Claude,接个国产模型照样跑得飞起。

我自己测试用的智谱 GLM-4,一个月 20 块钱,诊断了几十次集群问题,Token 才花了不到 5 块。

真香。

## 二. 再看 MCP Server - AI 的工具箱管家

Kubernetes MCP Server 就完全不一样了。

它不是主动去找问题,而是 **被动等着 AI Agent 来调用** 。

你可以把它理解成"AI 的工具箱管家"。

当你的 AI Agent(比如 Claude Code)想操作 K8s 集群时,它会通过 MCP 协议调用这个服务器,服务器提供各种工具(Tools)给 AI 用。

**核心工作流程**:

```
AI Agent 发起请求 → MCP Server 执行 → 返回结果给 AI
```

它提供的工具非常丰富:

**Core 工具集** \- 基础 K8s 操作:

- 列出 Pod、Service、Deployment
- 查看 Node 状态
- 获取 Events 日志
- 管理 Namespace

**Helm 工具集** \- 应用部署:

- 安装/卸载 Helm Chart
- 列出 Release
- 查看部署状态

**Kiali 工具集** \- 服务网格观测:

- 获取服务拓扑图
- 查看健康状态
- 分析流量指标

**KubeVirt 工具集** \- 虚拟机管理:

- 创建/删除虚拟机
- 控制 VM 生命周期
- 查询 VM 状态

**最亮的点是什么?**

它有个超完整的 **评估任务场景库** (evals/tasks),包含:

- Kubernetes 核心任务(金丝雀部署、网络策略、RBAC 配置)
- Kiali 服务网格任务
- KubeVirt 虚拟机管理任务

每个任务都有 setup.sh、verify.sh、cleanup.sh 脚本,可以自动验证 AI Agent 的执行结果对不对。

这对评测 AI Agent 的 K8s 操作能力来说,简直是神器。

## 三. 核心区别到底在哪?

说了这么多,它们的本质区别是啥?

我总结了个表格:

| 对比维度 | k8sgpt | Kubernetes MCP Server |
| --- | --- | --- |
| **定位** | 主动诊断工具 | 被动 API 服务 |
| **使用方式** | CLI 命令 + 可选服务器 | MCP 协议服务器 |
| **AI 角色** | 自己调用 AI 解释问题 | 为外部 AI 提供工具 |
| **功能范围** | 专注问题诊断 | 提供全面操作能力 |
| **适用场景** | 集群健康检查、问题排查 | AI Agent 自动化运维 |
| **学习成本** | 低,装上就能用 | 中等,需要理解 MCP 协议 |

**简单来说**:

- **k8sgpt** \= 自动化诊断医生,发现问题 → AI 解释 → 给建议
- **MCP Server** \= AI Agent 的后勤部,提供工具 → 等待调用 → 执行命令

一个是"主动看病",一个是"被动服务"。

## 四. 具体应该怎么选?

我测试下来,有几个建议:

**场景 1: 你只想快速排查集群问题**

直接用 **k8sgpt** 。

安装简单,几分钟就能跑起来:

```
# 安装
brew install k8sgpt

# 分析集群
k8sgpt analyze --explain

# 指定 AI 后端(比如用智谱 GLM)
k8sgpt auth add openai
```

它会自动扫描集群,把问题和 AI 解释一起输出,非常直观。

**场景 2: 你想让 AI Agent 自动化运维**

选 **MCP Server** 。

比如你用 Claude Code 管理集群,想让 AI 自己创建 Deployment、配置 Ingress、排查故障,这时候 MCP Server 就派上用场了。

它给 AI 提供了标准化的工具接口,AI 可以通过 MCP 协议调用各种 K8s 操作。

**场景 3: 你想评测 AI Agent 的 K8s 能力**

MCP Server 的 evals 任务场景库是必备的。

它提供了几十个标准化测试场景,可以自动验证 AI 的操作结果。

这对比较不同 AI 模型的 K8s 操作能力来说,非常有用。

**场景 4: 你的环境有特殊需求**

比如你需要:

- 集成 Prometheus 监控数据 → 用 **k8sgpt**
- 管理 Istio 服务网格 → 用 **MCP Server** (Kiali 工具集)
- 管理虚拟机 → 用 **MCP Server** (KubeVirt 工具集)

k8sgpt 通过外部集成支持 Prometheus、AWS EKS、KEDA、Kyverno。

MCP Server 通过工具集支持 Helm、Kiali、KubeVirt、KCP。

## 五. 我的实际测试

说点真实体验。

**测试 k8sgpt**:

我在测试集群故意搞坏了一个 Deployment:

```
spec:
  replicas: 3
  template:
    spec:
      containers:
      - image: nginx:lastest  # 拼写错误
```

运行 `k8sgpt analyze --explain`:

```
问题: Deployment nginx-test 副本数不匹配
详情: 期望 3 个副本,实际只有 0 个 Ready
AI 解释: 镜像拉取失败了。检查镜像名是否正确,
        "lastest" 应该是 "latest"。
        另外确认镜像仓库可访问性。
```

直接定位到问题,还给了修复建议。

整个过程不到 10 秒,Token 消耗不到 0.01 元。

**测试 MCP Server**:

我用 Claude Code 接入 MCP Server,然后给它一个任务:

```
创建一个金丝雀部署:
- stable 版本 3 个副本
- canary 版本 1 个副本
- 配置 Service 同时路由两个版本
```

Claude Code 通过 MCP Server 自动:

1. 创建了 stable Deployment
2. 创建了 canary Deployment
3. 配置了 Service selector
4. 验证了 Pod 启动状态

全程自动化,我只说了需求,AI 搞定一切。

## 六. 一些坑和建议

**k8sgpt 的坑**:

1. AI 解释质量依赖模型能力。用 GPT-4 和 GLM-4 差距还是有的,但 GLM-4 性价比高。
2. 敏感数据脱敏不够彻底。生产环境用建议开 `--anonymize` 参数。
3. 缓存机制有时候会返回过期解释。用 `--nocache` 可以强制刷新。

**MCP Server 的坑**:

1. 需要理解 MCP 协议,学习曲线比 k8sgpt 陡一些。
2. 权限管理要小心。默认它能操作整个集群,建议配置 RBAC 限制权限范围。
3. OpenTelemetry 追踪要单独配置。不配的话调试问题会比较麻烦。

**我的建议**:

1. **初学者先用 k8sgpt** 。简单直接,快速见效。
2. **运维老手可以都用** 。k8sgpt 日常巡检,MCP Server 自动化运维。
3. **AI 开发者重点关注 MCP Server** 。它是标准化 AI 工具集成的范例。

## 写在最后

贝联珠贯的 AIOps 系统确实很强,但开源世界也没闲着。

k8sgpt 和 MCP Server 虽然定位不同,但都在推动 AI + 运维的进化。

一个让问题诊断变简单,一个让自动化运维成为可能。

运维不会被 AI 取代,但会用 AI 的运维会取代不会用的。

与其担心饭碗,不如早点把这些工具用起来。

毕竟,工具就在那,免费开源,不用白不用。

好啦,感谢阅读,我们下一期见。

---

**参考链接**:

- k8sgpt GitHub: https://github.com/k8sgpt-ai/k8sgpt
- Kubernetes MCP Server GitHub: https://github.com/containers/kubernetes-mcp-server

以上,既然看到这里了,如果觉得不错,随手点个赞、在看、转发三连吧～

  

  

最后介绍下我的三门课程：

k8s源码专家训练营： 带你阅读 顶级开源项目源码，3 个月成为 P8 技术专家

大模型 AI Ops 训练营： Devops 到 FinOps 到 AIOps，运维开发升级之路 Agent 开发训练营： 以后都是 Agent 开发工程师，早点学，快人一步

  

  

  

  

  

继续滑动看下一个

CIT云原生

向上滑动看下一个